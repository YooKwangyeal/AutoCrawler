# ğŸ AutoCrawler/webapp/main.py
from fastapi import FastAPI, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse, FileResponse
import os
import subprocess
import glob
import base64

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

app = FastAPI()

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def read_index():
    return FileResponse("static/index.html")

@app.get("/crawl")
def crawl(query: str):
    query = query.strip()
    if not query:
        return JSONResponse(status_code=400, content={"error": "ë¹ˆ í‚¤ì›Œë“œ"})

    # keywords.txtì— ì €ì¥
    keyword_path = os.path.join(BASE_DIR, "keywords.txt")
    print("[DEBUG] keyword_path:", keyword_path)

    with open(keyword_path, "w", encoding="utf-8") as f:
        f.write(query)

    # AutoCrawler ì‹¤í–‰
    try:
        subprocess.run([
            "python3", "main.py",
            "--skip", "false",
            "--limit", "5",
            "--google", "true",
            "--naver", "true"
        ],
        cwd=os.path.join(BASE_DIR),
        check=True)
    except subprocess.CalledProcessError:
        return JSONResponse(status_code=500, content={"error": "í¬ë¡¤ë§ ì‹¤íŒ¨"})

    # ì´ë¯¸ì§€ ê²½ë¡œ íƒìƒ‰
    folder = os.path.join("..", "download", query)
    files = sorted(glob.glob(os.path.join(folder, "*.jpg")))[:5]

    if not files:
        return JSONResponse(status_code=404, content={"error": "ì´ë¯¸ì§€ ì—†ìŒ"})

    # base64ë¡œ ì¸ì½”ë”©í•´ì„œ ì „ë‹¬
    images = []
    for path in files:
        with open(path, "rb") as img_file:
            encoded = base64.b64encode(img_file.read()).decode("utf-8")
            images.append(f"data:image/jpeg;base64,{encoded}")

    return {"images": images}
